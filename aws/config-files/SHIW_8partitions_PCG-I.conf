dblink : {
    // Define distortion hyperparameters (to be referenced below)
    // numRecords = 39743
    lowDistortion : {alpha : 39.743, beta : 3974.3}

    // Define similarity functions (to be referenced below)
    constSimFn : {
        name : "ConstantSimilarityFn",
    }

    data : {
        // Path to data files. Must have header row (column names).
        path : "s3://d-blink/datasets/comp.fixed.0810.csv"

        // Specify columns that contain identifiers
        recordIdentifier : "RECID"
        fileIdentifier : "ANNO"
        entityIdentifier : "ENTID" // optional

        // String representation of a missing value
        nullValue : ""

        // Specify properties of the attributes (columns) used for matching
        matchingAttributes : [
            {name : "IREG", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "SESSO", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "ANASCI", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "STUDIO", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "PAR", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "STACIV", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "PERC", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "CFDIC", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}}
        ]
    }

    randomSeed : 319158
    expectedMaxClusterSize : 10
    
    // Specify partitioner
    partitioner : {
        name : "KDTreePartitioner",
        parameters : {
            numLevels : 3, // a value of zero means no partitioning
            matchingAttributes : ["ANASCI", "SESSO", "IREG", "STUDIO"] // cycle through matching attributes in this order when constructing the tree
        }
    }

    // Path to save Markov chain and full state (for resuming MCMC) + summaries
    outputPath : "hdfs:///dblink-output/"

    // Path to save Spark checkpoints
    checkpointPath : "hdfs:///dblink-checkpoints/"
    
    // Steps to be performed (in order)
    steps : [
        {name : "sample", parameters : {
            sampleSize : 10000,
            burninInterval : 0,
            thinningInterval : 10,
            resume : false,
            sampler : "PCG-I"
        }},
        {name : "summarize", parameters : {
            lowerIterationCutoff : 0,
            quantities : ["cluster-size-distribution", "partition-sizes"]
        }},
        {name : "evaluate", parameters : {
            lowerIterationCutoff : 10000,
            metrics : ["pairwise", "cluster"], 
            useExistingSMPC : false
        }},
        {name : "copy-files", parameters : {
            fileNames : ["cluster-size-distribution.csv", "partition-sizes.csv", "diagnostics.csv", "shared-most-probable-clusters.csv", "run.txt", "evaluation-results.txt"]
            destinationPath : "s3://d-blink/SHIW_8partitions_PCG-I/"
            overwrite : true,
            deleteSource : false
        }}
    ]
}
