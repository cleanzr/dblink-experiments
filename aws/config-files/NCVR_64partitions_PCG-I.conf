dblink : {

    // Define distortion hyperparameters (to be referenced below)
    // numRecords = 224073 + 224061 = 448134
    lowDistortion : {alpha : 448.134, beta : 44813.4}

    // Define similarity functions (to be referenced below)
    constSimFn : {
        name : "ConstantSimilarityFn",
    }

    levSimFn : {
        name : "LevenshteinSimilarityFn",
        parameters : {
            threshold : 7.0
            maxSimilarity : 10.0
        }
    }

    data : {
        // Path to data files. Must have header row (column names).
        path : "s3://d-blink/datasets/ncvoter-20140619-temporal-balanced-ratio-1to1.csv"

        // Specify columns that contain identifiers
        recordIdentifier : "rec_id"
        fileIdentifier : "file_id"
        entityIdentifier : "voter_id" // optional

        // String representation of a missing value
        nullValue : ""

        // Specify properties of the attributes (columns) used for matching
        matchingAttributes : [
            {name : "age", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "gender", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "zip_code", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "first_name", similarityFunction : ${dblink.levSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "middle_name", similarityFunction : ${dblink.levSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "last_name", similarityFunction : ${dblink.levSimFn}, distortionPrior : ${dblink.lowDistortion}}
        ]
    }

    randomSeed : 319158
    expectedMaxClusterSize : 10
    
    // Specify partitioner
    partitioner : {
        name : "KDTreePartitioner",
        parameters : {
            numLevels : 6, // a value of zero means no partitioning
            matchingAttributes : ["first_name", "last_name", "zip_code", "age"] // cycle through matching attributes in this order when constructing the tree
        }
    }

    // Path to save Markov chain and full state (for resuming MCMC) + summaries
    outputPath : "hdfs:///dblink-output/"

    // Path to save Spark checkpoints
    checkpointPath : "hdfs:///dblink-checkpoints/"
    
    // Steps to be performed (in order)
    steps : [
        {name : "sample", parameters : {
            sampleSize : 20000,
            burninInterval : 0,
            thinningInterval : 10,
            resume : false,
            sampler : "PCG-I"
        }},
        {name : "summarize", parameters : {
            lowerIterationCutoff : 0,
            quantities : ["cluster-size-distribution", "partition-sizes"]
        }},
        {name : "evaluate", parameters : {
            lowerIterationCutoff : 10000,
            metrics : ["pairwise", "cluster"], 
            useExistingSMPC : false
        }},
        {name : "copy-files", parameters : {
            fileNames : ["cluster-size-distribution.csv", "partition-sizes.csv", "diagnostics.csv", "shared-most-probable-clusters.csv", "run.txt", "evaluation-results.txt"]
            destinationPath : "s3://d-blink/NCVR_64partitions_PCG-I/"
            overwrite : true,
            deleteSource : false
        }}
    ]
}
