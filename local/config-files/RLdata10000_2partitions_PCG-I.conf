dblink : {
     // Define distortion hyperparameters (to be referenced below)
    lowDistortion : {alpha : 10.0, beta : 1000.0}

    // Define similarity functions (to be referenced below)
    constSimFn : {
        name : "ConstantSimilarityFn",
    }

    levSimFn : {
        name : "LevenshteinSimilarityFn",
        parameters : {
            threshold : 7.0
            maxSimilarity : 10.0
        }
    }

    data : {
        // Path to data files. Must have header row (column names).
        path : "/data/neil/datasets/RLdata10000.csv"

        // Specify columns that contain identifiers
        recordIdentifier : "rec_id",
        // fileIdentifier : null, // not needed since this data set is only a single file
        entityIdentifier : "ent_id" // optional

        // String representation of a missing value
        nullValue : "NA"

        // Specify properties of the attributes (columns) used for matching
        matchingAttributes : [
            {name : "by", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "bm", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "bd", similarityFunction : ${dblink.constSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "fname_c1", similarityFunction : ${dblink.levSimFn}, distortionPrior : ${dblink.lowDistortion}},
            {name : "lname_c1", similarityFunction : ${dblink.levSimFn}, distortionPrior : ${dblink.lowDistortion}}
        ]
    }

    randomSeed : 319158
    expectedMaxClusterSize : 10
    
    // Specify partitioner
    partitioner : {
        name : "KDTreePartitioner",
        properties : {
            numLevels : 1, // a value of zero means no partitioning
            matchingAttributes : ["fname_c1"] // cycle through matching attributes in this order when constructing the tree
        }
    }

    // Path to save Markov chain and full state (for resuming MCMC) + summaries
    outputPath : "/data/neil/jcgs/RLdata10000_2partitions_PCG-I"
    
    // Path to save Spark checkpoints
    checkpointPath : "/scratch/neil/dblink-checkpoints"
    
    // Steps to be performed (in order)
    steps : [
        {name : "sample", parameters : {
            sampleSize : 10000,
            burninInterval : 0,
            thinningInterval : 10,
            resume : false,
            sampler : "PCG-I"
        }},
        {name : "summarize", parameters : {
            lowerIterationCutoff : 0,
            quantities : ["cluster-size-distribution", "partition-sizes"]
        }},
        {name : "evaluate", parameters : {
            lowerIterationCutoff : 10000,
            metrics : ["pairwise", "cluster"], 
            useExistingSMPC : false
        }}
    ]
}
